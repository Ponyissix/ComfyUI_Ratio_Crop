# 重构交互逻辑：从“手动框选”到“智能蒙版裁切”

用户希望彻底改变现有的交互模式。不再是手动拖拽一个固定的框，而是**先涂抹感兴趣的区域（蒙版），然后系统自动根据涂抹区域生成最合适的裁切框**。

## 核心需求分析
1.  **输入**：用户在图片上涂抹（画笔操作）。
2.  **处理**：
    *   计算涂抹区域的最小外接矩形（Bounding Box）。
    *   应用**Padding（冗余宽度）**：向外扩展一定的像素。
    *   **比例匹配**：根据扩展后的矩形，自动匹配最接近的预设比例（或保持 Free），并调整框的大小以符合该比例。
3.  **输出**：最终的裁切框坐标和尺寸。

## 实施方案

### 1. 改造前端编辑器 (js/crop_ui.js)
目前的编辑器是基于 Canvas 的“矩形拖拽”模式。我们需要增加“画笔涂抹”模式。

*   **新增工具栏按钮**：
    *   `画笔 (Brush)`：用于涂抹蒙版。
    *   `橡皮 (Eraser)`：用于擦除蒙版。
    *   `画笔大小 (Size)`：滑块控制。
    *   `自动裁切 (Auto Crop)`：点击后执行计算逻辑。
    *   `Padding 输入框`：用户设定冗余像素值（默认例如 50px）。

*   **交互逻辑变更**：
    *   **初始状态**：显示原图。
    *   **操作**：用户涂抹出红色半透明的蒙版区域。
    *   **触发计算**：用户点击“生成裁切框”或每次涂抹结束自动计算。
    *   **计算算法**：
        1.  遍历 Mask 像素，找到 minX, minY, maxX, maxY。
        2.  应用 Padding：`minX -= padding, maxX += padding...`。
        3.  应用 Ratio：
            *   如果是 `Free`：直接使用 Padding 后的框。
            *   如果是固定比例（如 1:1）：计算当前框的中心点，根据比例向外扩展（取 max 边长或 fit 边长）直到满足比例且包含蒙版。
    *   **结果展示**：生成一个绿色的裁切框覆盖在蒙版之上。用户依然可以微调这个绿框（保留手动微调能力）。

### 2. 后端节点参数更新 (nodes.py)
*   **新增参数**：`mask_padding` (INT) - 虽然这个参数主要在前端交互时使用，但作为节点参数保存下来也是合理的，以便下次打开编辑器时记住设定。或者我们可以只在前端处理，后端只接收最终的坐标。
*   **建议**：为了保持后端简洁，`mask_padding` 作为一个前端交互参数即可，最终传给后端的依然是计算好的 `crop_x, crop_y, ...`。但如果用户希望这个 padding 能自动化流程化，那就需要在后端加参数。
*   **决策**：根据用户描述，“数值要能修改”，通常指在编辑器里修改。我们先在前端实现完整的闭环。

### 3. Mask 数据流
*   用户提到的“涂抹（作为蒙版）”主要用于**辅助生成裁切框**。
*   是否需要输出这个 Mask？用户之前的需求里有“移除 mask 输入”，但现在既然有了涂抹行为，输出这个 mask 给后续流程（如重绘）是非常有用的。
*   **增加输出**：`RatioCropNode` 应该增加一个 `MASK` 输出端口，输出用户涂抹的区域。

## 详细步骤计划
1.  **前端重写**：将 `js/crop_ui.js` 的编辑器模式从单一的“框选”改为“画笔+框选”混合模式。
2.  **增加 Mask 层**：在 Canvas 上增加一个独立的 Mask 图层用于绘制。
3.  **实现自动计算逻辑**：编写 JS 函数，根据 Mask 像素计算 Bounding Box 并适配 Ratio。
4.  **后端支持**：修改 `nodes.py`，增加 `MASK` 输出（可选，但强烈建议）。

请确认执行。